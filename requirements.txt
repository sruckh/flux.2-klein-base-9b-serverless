# RunPod Serverless Worker
runpod>=1.7.3

# PyTorch with CUDA 12.8 support (installed via pip in Dockerfile)
# torch==2.8.0
# torchvision==0.23.0
# torchaudio==2.8.0

# Diffusers and Transformers
diffusers @ git+https://github.com/huggingface/diffusers.git
transformers>=4.47.0
accelerate>=1.2.0
huggingface-hub>=0.28.0
peft>=0.14.0

# Flash Attention (installed via wheel in Dockerfile)
# flash_attn

# Image processing
Pillow>=11.1.0
safetensors>=0.4.6
spandrel>=0.4.0

# Sentence piece for tokenizers
sentencepiece>=0.2.0

# Optional: for progress bars
tqdm>=4.67.0

# fp8 quantization for transformer via optimum-quanto (documented diffusers approach
# for FLUX fp8; no compute capability restriction, installs without version conflicts)
optimum-quanto>=0.2.4

# Optional: for better performance
protobuf>=5.29.0

# S3 storage for image uploads
boto3>=1.35.0

# Prompt weighting support
compel>=2.0.0
